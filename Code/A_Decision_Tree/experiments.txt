Data set:
    28056 elements total
    Number of each label:
    Draws - 2796
    Checkmates - 27
    Moves until checkmate:
        1  - 78
        2  - 246
        3  - 81
        4  - 198
        5  - 471
        6  - 592
        7  - 683
        8  - 1433
        9  - 1712
        10 - 1985
        11 - 2854
        12 - 3597
        13 - 4194
        14 - 4553
        15 - 2166
        16 - 390


Mutual Information(Base Data):
    I(Random,Random) = 0.003

    I(W_k_c,Class) = 0.1653
    I(W_k_r,Class) = 0.2903
    I(W_r_c,Class) = 0.0501
    I(W_r_r,Class) = 0.0462
    I(B_k_c,Class) = 0.1851
    I(B_k_r,Class) = 0.3145

    These MIs show that data set is skewed

    I(Corner-Distance,Class) = 0.3328
    I(Edge-Distance,Class) = 0.2602
    I(Kings-Distance,Class):
        L1= 0.1068
        L2 = 0.1488
        L3 = 0.1546
        L4 = 0.1546
        L5 = 0.1546
        L10 = 0.1546
        L15 = 0.1546
        L18 = 0.1546
        L19 = 0.1546
        L20 = 0.1541
        L30 = 0.1522
        L50 = 0.1344
        L100 = 0.1264
        LInf = 0.1077
    I(Draw,Class) = 0.4679
    I(Checkmate,Class) = 0.0110

Use L3 norm!


Entropy(Base Data):
    H(Class) = 3.5042


Decision Tree:
    Base data:
        Tree has 27429 nodes. Perfect accuracy.
    Base data + meta-features:
        Tree has 26751 nodes for L2. Perfect accuracy.
        Tree has 27047 nodes for L3. Perfect accuracy.
    Meta-features-L3:
        Tree has 99 nodes. ~40% raw accuracy, 90% of values are within 3
        classes of actual value.
            Mean is 1.3828! Median is 1! Std is 1.6343. Good results!
            Mean of random data is 6.1 class difference. Median is 5.

    Want to build from meta-features-L3. There are 33 different L3 norm values,
     so treat it like a continuous variable to simplify the model.
        Tree has 115 nodes. Slightly less accuracy than multi-way norm, but not terribly significant.
        For continuous norm: Mean is 1.462. Median is 1. Std is 1.7786.

    Cross validation:
        Split the data into 10 pieces. For each of 10 runs, split the data into
        9/10 training data and 1/10 testing data.
            Mean = 1.39! Std = 1.63!

    5 parameter training / testing = all: Mean = 1.0627. Std = 1.4781
    5 parameter cross-validation: 263 nodes: Mean = 1.075. Std = 1.468